{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction to Logic Synthesis for AI\n",
    "--------------------\n",
    "\n",
    "Logic synthesis is a crucial process in digital circuit design where a high-level description of a system's behavior is transformed into a gate-level representation. In the context of AI, particularly deep learning, logic synthesis enables the efficient implementation of neural networks on hardware such as FPGAs and ASICs.\n",
    "\n",
    "This notebook uses the NNgen library to demonstrate how deep neural network models can be synthesized into hardware. NNgen is a versatile tool that converts neural network descriptions into hardware description languages like Verilog. This is essential for developing custom hardware accelerators that significantly enhance the performance and efficiency of AI models.\n",
    "\n",
    "Understanding how to synthesize AI models into hardware is vital for advancing AI applications, particularly in areas requiring high performance and low power consumption, such as embedded systems, edge computing, and real-time data processing.\n",
    "\n",
    "This notebook is based on the [NNgen tutorial](https://github.com/NNgen/nngen).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./.venv/lib/python3.12/site-packages (2.3.1)\n",
      "Requirement already satisfied: torchvision in ./.venv/lib/python3.12/site-packages (0.18.1)\n",
      "Requirement already satisfied: veriloggen in ./.venv/lib/python3.12/site-packages (2.3.0)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: onnx in ./.venv/lib/python3.12/site-packages (1.16.1)\n",
      "Requirement already satisfied: nngen in ./.venv/lib/python3.12/site-packages (1.3.4)\n",
      "Requirement already satisfied: np in ./.venv/lib/python3.12/site-packages (1.0.2)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./.venv/lib/python3.12/site-packages (from torch) (4.12.1)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.12/site-packages (from torch) (1.12.1)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.12/site-packages (from torch) (2024.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./.venv/lib/python3.12/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./.venv/lib/python3.12/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./.venv/lib/python3.12/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./.venv/lib/python3.12/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./.venv/lib/python3.12/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./.venv/lib/python3.12/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./.venv/lib/python3.12/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./.venv/lib/python3.12/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./.venv/lib/python3.12/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./.venv/lib/python3.12/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./.venv/lib/python3.12/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./.venv/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.venv/lib/python3.12/site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: pyverilog>=1.3.0 in ./.venv/lib/python3.12/site-packages (from veriloggen) (1.3.0)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in ./.venv/lib/python3.12/site-packages (from onnx) (5.27.1)\n",
      "Requirement already satisfied: ply>=3.4 in ./.venv/lib/python3.12/site-packages (from pyverilog>=1.3.0->veriloggen) (3.11)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision veriloggen numpy onnx nngen np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Neural Network Architecture with NNgen\n",
    "\n",
    "In this section, we define a simple deep neural network (DNN) model using the NNgen library.\n",
    "\n",
    "The network consists of:\n",
    "\n",
    "1. **Input Layer**: Defined as a placeholder for input data with dimensions 32x32x3 (e.g., an RGB image) and a batch size of 1.\n",
    "\n",
    "2. **First Convolutional Layer**:\n",
    "   - Weights (`w0`), biases (`b0`), and scales (`s0`) are initialized.\n",
    "   - A convolution operation (`conv2d`) is applied to the input, followed by ReLU activation and max pooling.\n",
    "\n",
    "3. **Second Convolutional Layer**:\n",
    "   - Similar to the first layer, with new weights (`w1`), biases (`b1`), and scales (`s1`).\n",
    "   - The output is reshaped to prepare for fully connected layers.\n",
    "\n",
    "4. **First Fully Connected Layer**:\n",
    "   - Weights (`w2`), biases (`b2`), and scales (`s2`) are defined.\n",
    "   - A matrix multiplication (`matmul`) is performed with ReLU activation.\n",
    "\n",
    "5. **Second Fully Connected Layer**:\n",
    "   - New weights (`w3`), biases (`b3`), and scales (`s3`) are set.\n",
    "   - The final matrix multiplication operation produces the output layer.\n",
    "\n",
    "This structure showcases the typical layers found in a convolutional neural network (CNN) and highlights how NNgen can be used to define each layer's operations and data types, preparing the model for efficient hardware synthesis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T13:22:59.728393Z",
     "start_time": "2024-06-07T13:22:59.482602Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "\n",
    "import nngen as ng\n",
    "\n",
    "\n",
    "# data types\n",
    "act_dtype = ng.int8\n",
    "weight_dtype = ng.int8\n",
    "bias_dtype = ng.int32\n",
    "scale_dtype = ng.int8\n",
    "batchsize = 1\n",
    "\n",
    "# input\n",
    "input_layer = ng.placeholder(dtype=act_dtype,\n",
    "                             shape=(batchsize, 32, 32, 3),  # N, H, W, C\n",
    "                             name='input_layer')\n",
    "\n",
    "# layer 0: conv2d (with bias and scale (= batchnorm)), relu, max_pool\n",
    "w0 = ng.variable(dtype=weight_dtype,\n",
    "                 shape=(64, 3, 3, 3),  # Och, Ky, Kx, Ich\n",
    "                 name='w0')\n",
    "b0 = ng.variable(dtype=bias_dtype,\n",
    "                 shape=(w0.shape[0],), name='b0')\n",
    "s0 = ng.variable(dtype=scale_dtype,\n",
    "                 shape=(w0.shape[0],), name='s0')\n",
    "\n",
    "a0 = ng.conv2d(input_layer, w0,\n",
    "               strides=(1, 1, 1, 1),\n",
    "               bias=b0,\n",
    "               scale=s0,\n",
    "               act_func=ng.relu,\n",
    "               dtype=act_dtype,\n",
    "               sum_dtype=ng.int32)\n",
    "\n",
    "a0p = ng.max_pool_serial(a0,\n",
    "                         ksize=(1, 2, 2, 1),\n",
    "                         strides=(1, 2, 2, 1))\n",
    "\n",
    "# layer 1: conv2d, relu, reshape\n",
    "w1 = ng.variable(weight_dtype,\n",
    "                 shape=(64, 3, 3, a0.shape[-1]),\n",
    "                 name='w1')\n",
    "b1 = ng.variable(bias_dtype,\n",
    "                 shape=(w1.shape[0],),\n",
    "                 name='b1')\n",
    "s1 = ng.variable(scale_dtype,\n",
    "                 shape=(w1.shape[0],),\n",
    "                 name='s1')\n",
    "\n",
    "a1 = ng.conv2d(a0p, w1,\n",
    "               strides=(1, 1, 1, 1),\n",
    "               bias=b1,\n",
    "               scale=s1,\n",
    "               act_func=ng.relu,\n",
    "               dtype=act_dtype,\n",
    "               sum_dtype=ng.int32)\n",
    "\n",
    "a1r = ng.reshape(a1, [batchsize, -1])\n",
    "\n",
    "# layer 2: full-connection, relu\n",
    "w2 = ng.variable(weight_dtype,\n",
    "                 shape=(256, a1r.shape[-1]),\n",
    "                 name='w2')\n",
    "b2 = ng.variable(bias_dtype,\n",
    "                 shape=(w2.shape[0],),\n",
    "                 name='b2')\n",
    "s2 = ng.variable(scale_dtype,\n",
    "                 shape=(w2.shape[0],),\n",
    "                 name='s2')\n",
    "\n",
    "a2 = ng.matmul(a1r, w2,\n",
    "               bias=b2,\n",
    "               scale=s2,\n",
    "               transposed_b=True,\n",
    "               act_func=ng.relu,\n",
    "               dtype=act_dtype,\n",
    "               sum_dtype=ng.int32)\n",
    "\n",
    "# layer 3: full-connection, relu\n",
    "w3 = ng.variable(weight_dtype,\n",
    "                 shape=(10, a2.shape[-1]),\n",
    "                 name='w3')\n",
    "b3 = ng.variable(bias_dtype,\n",
    "                 shape=(w3.shape[0],),\n",
    "                 name='b3')\n",
    "s3 = ng.variable(scale_dtype,\n",
    "                 shape=(w3.shape[0],),\n",
    "                 name='s3')\n",
    "\n",
    "# output\n",
    "output_layer = ng.matmul(a2, w3,\n",
    "                         bias=b3,\n",
    "                         scale=s3,\n",
    "                         transposed_b=True,\n",
    "                         name='output_layer',\n",
    "                         dtype=act_dtype,\n",
    "                         sum_dtype=ng.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Alternative) Import an Existing Model on a DNN Framework via ONNX\n",
    "\n",
    "Instead of explicit model construction, you can import an existing model via the ONNX-importer. This allows for leveraging pre-trained models from, e.g., [`torchvision`](https://pytorch.org/vision/stable/index.html).\n",
    "\n",
    "Then, translate the model into an ONNX file, which can be imported as an NNgen model definition using the `ng.from_onnx` method.\n",
    "\n",
    "Here's a brief example:\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# Download a pre-trained model from Torchvision\n",
    "model = torchvision.models.resnet18(weights='IMAGENET1K_V1')\n",
    "\n",
    "# PyTorch to ONNX\n",
    "onnx_filename = 'resnet18_imagenet.onnx'\n",
    "dummy_input = torch.randn(*act_shape).transpose(1, 3)\n",
    "input_names = ['act']\n",
    "output_names = ['out']\n",
    "model.eval()\n",
    "torch.onnx.export(model, dummy_input, onnx_filename,\n",
    "                  input_names=input_names, output_names=output_names)\n",
    "\n",
    "# ONNX to NNgen\n",
    "dtypes = {}\n",
    "(outputs, placeholders, variables,\n",
    " constants, operators) = ng.from_onnx(onnx_filename,\n",
    "                                      value_dtypes=dtypes,\n",
    "                                      default_placeholder_dtype=act_dtype,\n",
    "                                      default_variable_dtype=weight_dtype,\n",
    "                                      default_constant_dtype=weight_dtype,\n",
    "                                      default_operator_dtype=act_dtype,\n",
    "                                      default_scale_dtype=scale_dtype,\n",
    "                                      default_bias_dtype=bias_dtype,\n",
    "                                      disable_fusion=disable_fusion)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning Random Values and Quantizing Weights\n",
    "\n",
    "In this example, we assign random floating-point values to the network weights and biases for demonstration purposes. In a real-world scenario, you would use actual trained weight values from a deep neural network framework.\n",
    "\n",
    "### Weight Initialization\n",
    "We initialize the weights and biases with random values clipped between -3.0 and 3.0. Scales are set to 1. This is done for all layers of the network.\n",
    "\n",
    "### Quantization\n",
    "\n",
    "To prepare the model for hardware synthesis, we use NNgen’s quantizer to convert these floating-point weights to integers. This process involves:\n",
    "\n",
    "- Setting scale factors based on activation data type width.\n",
    "- Normalizing the input data using ImageNet mean and standard deviation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T13:23:04.606154Z",
     "start_time": "2024-06-07T13:23:04.134206Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def initialize_weight(shape):\n",
    "    value = np.random.normal(size=np.prod(shape)).reshape(shape)\n",
    "    value = np.clip(value, -3.0, 3.0)\n",
    "    return value\n",
    "\n",
    "def initialize_bias(shape):\n",
    "    value = np.random.normal(size=np.prod(shape)).reshape(shape)\n",
    "    value = np.clip(value, -3.0, 3.0)\n",
    "    return value\n",
    "\n",
    "def initialize_scale(shape):\n",
    "    return np.ones(shape)\n",
    "\n",
    "def set_values(variables, init_function):\n",
    "    for var in variables:\n",
    "        var.set_value(init_function(var.shape))\n",
    "\n",
    "# Initialize weights\n",
    "weights = [w0, w1, w2, w3]\n",
    "set_values(weights, initialize_weight)\n",
    "\n",
    "# Initialize biases\n",
    "biases = [b0, b1, b2, b3]\n",
    "set_values(biases, initialize_bias)\n",
    "\n",
    "# Initialize scales\n",
    "scales = [s0, s1, s2, s3]\n",
    "set_values(scales, initialize_scale)\n",
    "\n",
    "# Quantizing the floating-point weights using the NNgen quantizer\n",
    "imagenet_mean = np.array([0.485, 0.456, 0.406]).astype(np.float32)\n",
    "imagenet_std = np.array([0.229, 0.224, 0.225]).astype(np.float32)\n",
    "\n",
    "act_scale_factor = 128 if act_dtype.width > 8 else int(round(2 ** (act_dtype.width - 1) * 0.5))\n",
    "\n",
    "input_scale_factors = {'input_layer': act_scale_factor}\n",
    "input_means = {'input_layer': imagenet_mean * act_scale_factor}\n",
    "input_stds = {'input_layer': imagenet_std * act_scale_factor}\n",
    "\n",
    "ng.quantize([output_layer], input_scale_factors, input_means, input_stds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning Hardware Attributes\n",
    "\n",
    "In deep learning, models are typically executed on hardware with parallel processing capabilities to speed up computations. This is particularly important when dealing with large datasets and complex models, where performance can be a bottleneck.\n",
    "\n",
    "The code cell assigns hardware attributes to different layers of a neural network model to optimize performance. These attributes configure the degree of parallelism in various directions (input channels, output channels, pixel columns, and rows) and the right-shift amount for integer precision execution.\n",
    "\n",
    "### Key Attributes:\n",
    "\n",
    "**Parallelism**:\n",
    "- `par_ich`: Parallelism in input channels. More input channels processed simultaneously.\n",
    "- `par_och`: Parallelism in output channels. More output channels processed simultaneously.\n",
    "\n",
    "### Why It's Important:\n",
    "\n",
    "**Performance**: By configuring parallelism, the model can leverage hardware capabilities to process multiple operations simultaneously, leading to faster execution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T13:23:09.454511Z",
     "start_time": "2024-06-07T13:23:09.448612Z"
    }
   },
   "outputs": [],
   "source": [
    "par_ich = 2\n",
    "par_och = 2\n",
    "\n",
    "a0.attribute(par_ich=par_ich, par_och=par_och)\n",
    "a1.attribute(par_ich=par_ich, par_och=par_och)\n",
    "a2.attribute(par_ich=par_ich, par_och=par_och)\n",
    "output_layer.attribute(par_ich=par_ich, par_och=par_och)\n",
    "\n",
    "par = par_och\n",
    "\n",
    "a0p.attribute(par=par)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify the DNN Model Behavior by Executing the NNgen Dataflow as Software\n",
    "\n",
    "After assigning weight values, the constructed NNgen dataflow can be executed as software to verify the behavior of a quantized DNN model. The `ng.eval` method evaluates the NNgen dataflow according to input values provided via method arguments.\n",
    "\n",
    "In this example, random integer values are produced by NumPy and assigned as an input. However, in practice, actual integer input values, such as image data opened by PIL, should be used.\n",
    "\n",
    "### Steps:\n",
    "1. Generate Input Values:\n",
    "    - Random integer values are generated using NumPy.\n",
    "    - The values are then clipped and scaled to fit the expected range for the input layer.\n",
    "    - The values are rounded and converted to the appropriate integer type.\n",
    "\n",
    "2. Evaluate the Model:\n",
    "    - The `ng.eval` method is called with the input values to evaluate the NNgen dataflow.\n",
    "    - The output of the model is captured and printed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T13:23:12.099417Z",
     "start_time": "2024-06-07T13:23:12.001610Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 11  -2  25 -11  -1  12   7   0  -3  -4]]\n"
     ]
    }
   ],
   "source": [
    "input_layer_value = np.random.normal(size=input_layer.length).reshape(input_layer.shape)\n",
    "input_layer_value = input_layer_value * imagenet_std + imagenet_mean\n",
    "input_layer_value = np.clip(input_layer_value, -3.0, 3.0)\n",
    "input_layer_value = input_layer_value * act_scale_factor\n",
    "input_layer_value = np.clip(input_layer_value,\n",
    "                            -1 * 2 ** (act_dtype.width - 1) - 1, 2 ** (act_dtype.width - 1))\n",
    "input_layer_value = np.round(input_layer_value).astype(np.int64)\n",
    "\n",
    "eval_outs = ng.eval([output_layer], input_layer=input_layer_value)\n",
    "output_layer_value = eval_outs[0]\n",
    "\n",
    "print(output_layer_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the NNgen dataflow to a hardware description (Verilog HDL and IP-XACT)\n",
    "\n",
    "After all the weights are assigned and the hardware attributes are configured, the NNgen dataflow is ready to be converted to an actual hardware description.\n",
    "\n",
    "You can specify the hardware parameters, such as a data width of the AXI interface and system-wide signal names, via the \"config\" argument. Please see \"nngen/verilog.py\" for all the list of configurable hardware parameters.\n",
    "\n",
    "NNgen generates an all-inclusive dedicated hardware design for an input DNN model, which includes parallel processing elements, on-chip memories, on-chip network between the processing elements and the on-chip memories, a DMA controller between off-chip memories and on-chip memories, and FSM-based control circuits. Therefore, no external control, such as DMA on CPU is required after the generated hardware begins a computation.\n",
    "\n",
    "NNgen supports 3 types of output: 1) Veriloggen object, which is Python-based high-level hardware abstraction, 2) IP-XACT, which is a common IP-core format, and 3) Verilog HDL RTL as a text file.\n",
    "A generated Veriloggen object can be easily verified by a testing mechanism of Veriloggen and a Verilog simulator.\n",
    "A generated IP-XACT IP-core can be integrated with other components via AMBA AXI4 interface on an FPGA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T13:23:24.399582Z",
     "start_time": "2024-06-07T13:23:14.733626Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNgen: Neural Network Accelerator Generator (version 1.3.4)\n",
      "[IP-XACT]\n",
      "  Output: dnn_accelerator\n",
      "[Configuration]\n",
      "(AXI Master Interface)\n",
      "  Data width   : 32\n",
      "  Address width: 32\n",
      "(AXI Slave Interface)\n",
      "  Data width   : 32\n",
      "  Address width: 32\n",
      "[Schedule Table]\n",
      "(Stage 0)\n",
      "(Stage 1)\n",
      "  <conv2d None dtype:int8 shape:(1, 32, 32, 64) strides:(1, 1, 1, 1) padding:'SAME'-(1, 1, 1, 1) bias:(64,) scale:(64,) cshamt_out:17 act_func:relu sum_dtype:int32 par_ich:2 par_och:2 concur_och:16 stationary:filter keep_input default_addr:4242240 g_index:0 l_index:1 word_alignment:4 aligned_shape:(1, 32, 32, 64) scale_factor:2.625163>\n",
      "  | <placeholder input_layer dtype:int8 shape:(1, 32, 32, 3) default_addr:64 g_index:2 word_alignment:4 aligned_shape:(1, 32, 32, 4) scale_factor:64.000000>\n",
      "  | <variable w0 dtype:int8 shape:(64, 3, 3, 3) default_addr:4160 g_index:3 word_alignment:4 aligned_shape:(64, 3, 3, 4) scale_factor:42.333333>\n",
      "  | <variable b0 dtype:int32 shape:(64,) default_addr:4160 g_index:3 word_alignment:2 aligned_shape:(64,) scale_factor:2709.333333>\n",
      "  | <variable s0 dtype:int8 shape:(64,) default_addr:4160 g_index:3 word_alignment:4 aligned_shape:(64,) scale_factor:127.000000>\n",
      "(Stage 2)\n",
      "  <max_pool_serial None dtype:int8 shape:(1, 16, 16, 64) ksize:(1, 2, 2, 1) strides:(1, 2, 2, 1) padding:'SAME'-(0, 0, 0, 0) par:2 no_reuse default_addr:4307776 g_index:0 l_index:2 word_alignment:4 aligned_shape:(1, 16, 16, 64) scale_factor:2.625163>\n",
      "  | <conv2d None dtype:int8 shape:(1, 32, 32, 64) strides:(1, 1, 1, 1) padding:'SAME'-(1, 1, 1, 1) bias:(64,) scale:(64,) cshamt_out:17 act_func:relu sum_dtype:int32 par_ich:2 par_och:2 concur_och:16 stationary:filter keep_input default_addr:4242240 g_index:0 l_index:1 word_alignment:4 aligned_shape:(1, 32, 32, 64) scale_factor:2.625163>\n",
      "(Stage 3)\n",
      "  <conv2d None dtype:int8 shape:(1, 16, 16, 64) strides:(1, 1, 1, 1) padding:'SAME'-(1, 1, 1, 1) bias:(64,) scale:(64,) cshamt_out:16 act_func:relu sum_dtype:int32 par_ich:2 par_och:2 concur_och:16 stationary:filter default_addr:4324160 g_index:0 l_index:3 word_alignment:4 aligned_shape:(1, 16, 16, 64) scale_factor:0.215359>\n",
      "  | <max_pool_serial None dtype:int8 shape:(1, 16, 16, 64) ksize:(1, 2, 2, 1) strides:(1, 2, 2, 1) padding:'SAME'-(0, 0, 0, 0) par:2 no_reuse default_addr:4307776 g_index:0 l_index:2 word_alignment:4 aligned_shape:(1, 16, 16, 64) scale_factor:2.625163>\n",
      "  | <variable w1 dtype:int8 shape:(64, 3, 3, 64) default_addr:4160 g_index:3 word_alignment:4 aligned_shape:(64, 3, 3, 64) scale_factor:42.333333>\n",
      "  | <variable b1 dtype:int32 shape:(64,) default_addr:4160 g_index:3 word_alignment:2 aligned_shape:(64,) scale_factor:111.131890>\n",
      "  | <variable s1 dtype:int8 shape:(64,) default_addr:4160 g_index:3 word_alignment:4 aligned_shape:(64,) scale_factor:127.000000>\n",
      "(Stage 4)\n",
      "  <_lazy_reshape None dtype:int8 shape:(1, 16384) alias_of:<conv2d> default_addr:4324160 g_index:0 l_index:3 word_alignment:4 aligned_shape:(1, 16384) scale_factor:0.215359>\n",
      "  | <conv2d None dtype:int8 shape:(1, 16, 16, 64) strides:(1, 1, 1, 1) padding:'SAME'-(1, 1, 1, 1) bias:(64,) scale:(64,) cshamt_out:16 act_func:relu sum_dtype:int32 par_ich:2 par_och:2 concur_och:16 stationary:filter default_addr:4324160 g_index:0 l_index:3 word_alignment:4 aligned_shape:(1, 16, 16, 64) scale_factor:0.215359>\n",
      "(Stage 5)\n",
      "  <matmul None dtype:int8 shape:(1, 256) bias:(256,) scale:(256,) cshamt_out:19 act_func:relu sum_dtype:int32 par_left_col:2 par_out_col:2 concur_out_col:4 stationary:right keep_left default_addr:4340544 g_index:0 l_index:4 word_alignment:4 aligned_shape:(1, 256) scale_factor:0.002208>\n",
      "  | <_lazy_reshape None dtype:int8 shape:(1, 16384) alias_of:<conv2d> default_addr:4324160 g_index:0 l_index:3 word_alignment:4 aligned_shape:(1, 16384) scale_factor:0.215359>\n",
      "  | <variable w2 dtype:int8 shape:(256, 16384) default_addr:4160 g_index:3 word_alignment:4 aligned_shape:(256, 16384) scale_factor:42.333333>\n",
      "  | <variable b2 dtype:int32 shape:(256,) default_addr:4160 g_index:3 word_alignment:2 aligned_shape:(256,) scale_factor:9.116853>\n",
      "  | <variable s2 dtype:int8 shape:(256,) default_addr:4160 g_index:3 word_alignment:4 aligned_shape:(256,) scale_factor:127.000000>\n",
      "(Stage 6)\n",
      "  <matmul output_layer dtype:int8 shape:(1, 10) bias:(10,) scale:(10,) cshamt_out:16 sum_dtype:int32 par_left_col:2 par_out_col:2 concur_out_col:256 stationary:right keep_left keep_right default_addr:0 g_index:1 word_alignment:4 aligned_shape:(1, 12) scale_factor:0.000181>\n",
      "  | <matmul None dtype:int8 shape:(1, 256) bias:(256,) scale:(256,) cshamt_out:19 act_func:relu sum_dtype:int32 par_left_col:2 par_out_col:2 concur_out_col:4 stationary:right keep_left default_addr:4340544 g_index:0 l_index:4 word_alignment:4 aligned_shape:(1, 256) scale_factor:0.002208>\n",
      "  | <variable w3 dtype:int8 shape:(10, 256) default_addr:4160 g_index:3 word_alignment:4 aligned_shape:(10, 256) scale_factor:42.333333>\n",
      "  | <variable b3 dtype:int32 shape:(10,) default_addr:4160 g_index:3 word_alignment:2 aligned_shape:(10,) scale_factor:0.093489>\n",
      "  | <variable s3 dtype:int8 shape:(10,) default_addr:4160 g_index:3 word_alignment:4 aligned_shape:(12,) scale_factor:127.000000>\n",
      "[RAM (spec: num)]\n",
      "  64-bit 256-entry 2-port 1-bank RAM: 1\n",
      "  16-bit 32768-entry 2-port 2-bank RAM: 2\n",
      "  16-bit 8192-entry 2-port 2-bank RAM: 1\n",
      "  16-bit 512-entry 2-port 2-bank RAM: 31\n",
      "[Substream (spec: num)]\n",
      "  ('acc_rshift_round_frac', (32, 0, True, 32, 0, True)): 2\n",
      "  ('add_tree', (32, 0, True, 2)): 2\n",
      "  ('add_tree', (32, 0, True, 18)): 2\n",
      "  ('mul_rshift_round_clip', (32, 0, True, 8, 0, True, 40, 0, True, 8, 0, True, False)): 2\n",
      "  ('mul_rshift_round_madd', (8, 0, True, 8, 0, True, 16, 0, True)): 36\n",
      "  ('reduce_max', (8, 0, True)): 2\n",
      "[Stream (spec: num)]\n",
      "  (((<class 'nngen.operator.conv2d.conv2d'>, <dtype int8>, <dtype int8>, <dtype int32>, <dtype int8>), <dtype int8>, 1), 3, 3, False, None, <dtype int32>, 2, 2, 1, 1, 9, 36): 1\n",
      "  (((<class 'nngen.operator.pool_serial.max_pool_serial'>, <dtype int8>), <dtype int8>, 2), 2, 2, True, 2): 1\n",
      "  (((<class 'nngen.operator.basic._lazy_reshape'>, <dtype int8>), <dtype int8>, 1), True): 1\n",
      "  (((<class 'nngen.operator.matmul.matmul'>, <dtype int8>, <dtype int8>, <dtype int32>, <dtype int8>), <dtype int8>, 1), 1, 1, False, None, <dtype int32>, 2, 2, 1, 1, 1, 4): 1\n",
      "[State IDs in main_fsm]\n",
      "  (3, 4, 'input_layer', 'None')\n",
      "  (12, 14, None, 'control_conv2d_4')\n",
      "  (18, 20, None, 'control_max_pool_serial_6')\n",
      "  (28, 30, None, 'control_conv2d_4')\n",
      "  (31, 32, None, 'None')\n",
      "  (40, 42, None, 'control_matmul_16')\n",
      "  (50, 52, 'output_layer', 'control_matmul_16')\n",
      "[Control (name (# states: num))]\n",
      "  main_fsm (# states: 58)\n",
      "  control_conv2d_4 (# states: 35)\n",
      "  control_max_pool_serial_6 (# states: 20)\n",
      "  control_matmul_16 (# states: 29)\n",
      "[Register Map]\n",
      "    0 (R ): header0 (default: 0x00000000)\n",
      "    4 (R ): header1 (default: 0x00000000)\n",
      "    8 (R ): header2 (default: 0x00000000)\n",
      "   12 (R ): header3 (default: 0x00000000)\n",
      "   16 ( W): Start (set '1' to run)\n",
      "   20 (R ): Busy (returns '1' when running)\n",
      "   24 ( W): Reset (set '1' to initialize internal logic)\n",
      "   28 (R ): Opcode from extern objects to SW (returns '0' when idle)\n",
      "   32 ( W): Resume extern objects (set '1' to resume)\n",
      "   36 (R ): Interrupt Status Register\n",
      "   40 ( W): Interrupt Enable Register\n",
      "   44 ( W): Interrupt Acknowledge Register\n",
      "   48 (R ): State Counter\n",
      "   52 ( W): Count Target\n",
      "   56 ( W): Count Divider\n",
      "   60 (  ): Reserved ...\n",
      "  120 (  ): ... Reserved\n",
      "  124 (R ): Address space amount\n",
      "  128 (RW): Global address offset (default: 0)\n",
      "  132 (RW): Address of temporal storages (size: 97KB)\n",
      "  136 (RW): Address of output (matmul) 'output_layer' (size: 64B, dtype: int8, shape: (1, 10), alignment: 4 words (4 bytes)), aligned shape: (1, 12)\n",
      "  140 (RW): Address of placeholder 'input_layer' (size: 4KB, dtype: int8, shape: (1, 32, 32, 3), alignment: 4 words (4 bytes)), aligned shape: (1, 32, 32, 4)\n",
      "  144 (RW): Address of variables 'w0', 'b0', 's0', 'w1', 'b1', 's1', 'w2', 'b2', 's2', 'w3', 'b3', 's3' (size: 4139KB)\n",
      "[Default Memory Map (start - end)] (entire range: [0 - 4340799], size: 4240KB)\n",
      "  [      0 -      63]: output (matmul) 'output_layer' (size: 64B, dtype: int8, shape: (1, 10), alignment: 4 words (4 bytes)), aligned shape: (1, 12)\n",
      "  [     64 -    4159]: placeholder 'input_layer' (size: 4KB, dtype: int8, shape: (1, 32, 32, 3), alignment: 4 words (4 bytes)), aligned shape: (1, 32, 32, 4)\n",
      "  [   4160 -    6463]: variable 'w0' (size: 3KB, dtype: int8, shape: (64, 3, 3, 3), alignment: 4 words (4 bytes)), aligned shape: (64, 3, 3, 4)\n",
      "  [   6464 -    6719]: variable 'b0' (size: 256B, dtype: int32, shape: (64,), alignment: 2 words (8 bytes)), aligned shape: (64,)\n",
      "  [   6720 -    6783]: variable 's0' (size: 64B, dtype: int8, shape: (64,), alignment: 4 words (4 bytes)), aligned shape: (64,)\n",
      "  [   6784 -   43647]: variable 'w1' (size: 36KB, dtype: int8, shape: (64, 3, 3, 64), alignment: 4 words (4 bytes)), aligned shape: (64, 3, 3, 64)\n",
      "  [  43648 -   43903]: variable 'b1' (size: 256B, dtype: int32, shape: (64,), alignment: 2 words (8 bytes)), aligned shape: (64,)\n",
      "  [  43904 -   43967]: variable 's1' (size: 64B, dtype: int8, shape: (64,), alignment: 4 words (4 bytes)), aligned shape: (64,)\n",
      "  [  43968 - 4238271]: variable 'w2' (size: 4096KB, dtype: int8, shape: (256, 16384), alignment: 4 words (4 bytes)), aligned shape: (256, 16384)\n",
      "  [4238272 - 4239295]: variable 'b2' (size: 1KB, dtype: int32, shape: (256,), alignment: 2 words (8 bytes)), aligned shape: (256,)\n",
      "  [4239296 - 4239551]: variable 's2' (size: 256B, dtype: int8, shape: (256,), alignment: 4 words (4 bytes)), aligned shape: (256,)\n",
      "  [4239552 - 4242111]: variable 'w3' (size: 3KB, dtype: int8, shape: (10, 256), alignment: 4 words (4 bytes)), aligned shape: (10, 256)\n",
      "  [4242112 - 4242175]: variable 'b3' (size: 64B, dtype: int32, shape: (10,), alignment: 2 words (8 bytes)), aligned shape: (10,)\n",
      "  [4242176 - 4242239]: variable 's3' (size: 64B, dtype: int8, shape: (10,), alignment: 4 words (4 bytes)), aligned shape: (12,)\n",
      "  [4242240 - 4340799]: temporal storages (size: 97KB)\n",
      "# IP-XACT was generated. Check the current directory.\n"
     ]
    }
   ],
   "source": [
    "silent = False\n",
    "axi_datawidth = 32\n",
    "\n",
    "# to Veriloggen object\n",
    "# targ = ng.to_veriloggen([output_layer], 'dnn_accelerator', silent=silent,\n",
    "#                        config={'maxi_datawidth': axi_datawidth})\n",
    "\n",
    "# to IP-XACT (the method returns Veriloggen object, as well as to_veriloggen)\n",
    "targ = ng.to_ipxact([output_layer], 'dnn_accelerator', silent=silent,\n",
    "                    config={'maxi_datawidth': axi_datawidth})\n",
    "print('# IP-XACT was generated. Check the current directory.')\n",
    "\n",
    "# to Verilog HDL RTL (the method returns a source code text)\n",
    "# rtl = ng.to_verilog([output_layer], 'dnn_accelerator', silent=silent,\n",
    "#                    config={'maxi_datawidth': axi_datawidth})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the quantized weights\n",
    "\n",
    "All weight parameters are zipped into a single `np.ndarray` by the `ng.export_ndarray` method. This array can be utilized in an actual FPGA platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T13:23:48.884226Z",
     "start_time": "2024-06-07T13:23:47.307951Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert weight values to a memory image:\n",
    "# on a real FPGA platform, this image will be used as a part of the model definition.\n",
    "param_filename = 'dnn_accelerator.npz'\n",
    "chunk_size = 64\n",
    "\n",
    "param_data = ng.export_ndarray([output_layer], chunk_size)\n",
    "np.savez_compressed(param_filename, param_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate the generated hardware by Veriloggen and Verilog simulator\n",
    "\n",
    "If you want to reduce the development time, you can skip this section for Verilog simulation.\n",
    "\n",
    "If you generate a hardware as Veriloggen object or IP-XACT, you can simulate the hardware behavior on Verilog simulator via the testing mechanism on Veriloggen.\n",
    "\n",
    "Before the hardware runs, the input data and weight values should be located on the shared off-chip memory. In Verilog simulation in the example, there is a `np.ndarray` object to represent a dump image of the off-chip memory. You can copy the pre-computed values to the memory image by `axi.set_memory` method.\n",
    "\n",
    "`param_data` is the unified parameter data of all variables and constants. Locations of the located data are configurable, which can be changed from the CPU via the configuration register of the NNgen hardware. In the following example, the head address of unified parameter data (`variable_addr`) is calculated by the same rule as the address calculator in the NNgen compiler.\n",
    "\n",
    "The `ctrl` method in the following example is an emulation of a control program on the CPU, which is actually an FSM circuit of the control sequence synthesized by the procedural high-level synthesis compiler of Veriloggen. Via the `ng.sim.start` method, the program writes `1` to the `start` register of the NNgen hardware. Then, the hardware begins the computation, and the CPU waits until the computation finishes via the `ng.sim.wait` method.\n",
    "\n",
    "### Data alignment, `word_alignment`, and `aligned_shape`\n",
    "\n",
    "**Note that all the input, weight, and output data should be located along with their alignments.** Especially, using a narrower data width (for any data) than the AXI interconnect interface and applying the parallelization via the hardware attribute will require special cares of data arrangement. In a synthesis log, you can find the `word_alignment` and `aligned_shape` for each placeholder, variable, operator. When putting corresponding data on an off-chip memory, a padding will be required according to the word alignment. The difference between the original shape and the aligned shape is the size of padding. In NNgen, padding is required only at an innermost dimension.\n",
    "\n",
    "Unified variable images, such as `param_data`, are already aligned according to the word alignment. So you don't have to rearrange the data alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T13:24:50.939626Z",
     "start_time": "2024-06-07T13:24:05.504444Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# start\n",
      "# end\n",
      "# execution cycles:     1788938\n",
      "OK (           0           0 ) orig:           11  check:           11\n",
      "OK (           0           1 ) orig:            1  check:            1\n",
      "OK (           0           2 ) orig:          -24  check:          -24\n",
      "OK (           0           3 ) orig:           -2  check:           -2\n",
      "OK (           0           4 ) orig:            2  check:            2\n",
      "OK (           0           5 ) orig:           20  check:           20\n",
      "OK (           0           6 ) orig:          -22  check:          -22\n",
      "OK (           0           7 ) orig:           -4  check:           -4\n",
      "OK (           0           8 ) orig:            1  check:            1\n",
      "OK (           0           9 ) orig:           14  check:           14\n",
      "# verify: PASSED\n",
      "- /home/marcel/git/lsforai/hello_nngen.out/out.v:1528: Verilog $finish\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from veriloggen import *\n",
    "import veriloggen.thread as vthread\n",
    "import veriloggen.types.axi as axi\n",
    "\n",
    "outputfile = 'dnn_accelerator.out'\n",
    "filename = 'dnn_accelerator.v'\n",
    "# simtype = 'iverilog'\n",
    "simtype = 'verilator'\n",
    "\n",
    "param_bytes = len(param_data)\n",
    "\n",
    "variable_addr = int(\n",
    "    math.ceil((input_layer.addr + input_layer.memory_size) / chunk_size)) * chunk_size\n",
    "check_addr = int(math.ceil((variable_addr + param_bytes) / chunk_size)) * chunk_size\n",
    "tmp_addr = int(math.ceil((check_addr + output_layer.memory_size) / chunk_size)) * chunk_size\n",
    "\n",
    "memimg_datawidth = 32\n",
    "mem = np.zeros([1024 * 1024 * 256 // memimg_datawidth], dtype=np.int64)\n",
    "mem = mem + [100]\n",
    "\n",
    "# placeholder\n",
    "axi.set_memory(mem, input_layer_value, memimg_datawidth,\n",
    "               act_dtype.width, input_layer.addr,\n",
    "               max(int(math.ceil(axi_datawidth / act_dtype.width)), par_ich))\n",
    "\n",
    "# parameters (variable and constant)\n",
    "axi.set_memory(mem, param_data, memimg_datawidth,\n",
    "               8, variable_addr)\n",
    "\n",
    "# verification data\n",
    "axi.set_memory(mem, output_layer_value, memimg_datawidth,\n",
    "               act_dtype.width, check_addr,\n",
    "               max(int(math.ceil(axi_datawidth / act_dtype.width)), par_och))\n",
    "\n",
    "# test controller\n",
    "m = Module('test')\n",
    "params = m.copy_params(targ)\n",
    "ports = m.copy_sim_ports(targ)\n",
    "clk = ports['CLK']\n",
    "resetn = ports['RESETN']\n",
    "rst = m.Wire('RST')\n",
    "rst.assign(Not(resetn))\n",
    "\n",
    "# AXI memory model\n",
    "if outputfile is None:\n",
    "    outputfile = os.path.splitext(os.path.basename(__file__))[0] + '.out'\n",
    "\n",
    "memimg_name = 'memimg_' + outputfile\n",
    "\n",
    "memory = axi.AxiMemoryModel(m, 'memory', clk, rst,\n",
    "                            datawidth=axi_datawidth,\n",
    "                            memimg=mem, memimg_name=memimg_name,\n",
    "                            memimg_datawidth=memimg_datawidth)\n",
    "memory.connect(ports, 'maxi')\n",
    "\n",
    "# AXI-Slave controller\n",
    "_saxi = vthread.AXIMLite(m, '_saxi', clk, rst, noio=True)\n",
    "_saxi.connect(ports, 'saxi')\n",
    "\n",
    "# timer\n",
    "time_counter = m.Reg('time_counter', 32, initval=0)\n",
    "seq = Seq(m, 'seq', clk, rst)\n",
    "seq(\n",
    "    time_counter.inc()\n",
    ")\n",
    "\n",
    "\n",
    "def ctrl():\n",
    "    for i in range(100):\n",
    "        pass\n",
    "\n",
    "    ng.sim.set_global_addrs(_saxi, tmp_addr)\n",
    "\n",
    "    start_time = time_counter.value\n",
    "    ng.sim.start(_saxi)\n",
    "\n",
    "    print('# start')\n",
    "\n",
    "    ng.sim.wait(_saxi)\n",
    "    end_time = time_counter.value\n",
    "\n",
    "    print('# end')\n",
    "    print('# execution cycles: %d' % (end_time - start_time))\n",
    "\n",
    "    # verify\n",
    "    ok = True\n",
    "    for bat in range(output_layer.shape[0]):\n",
    "        for x in range(output_layer.shape[1]):\n",
    "            orig = memory.read_word(bat * output_layer.aligned_shape[1] + x,\n",
    "                                    output_layer.addr, act_dtype.width)\n",
    "            check = memory.read_word(bat * output_layer.aligned_shape[1] + x,\n",
    "                                     check_addr, act_dtype.width)\n",
    "\n",
    "            if vthread.verilog.NotEql(orig, check):\n",
    "                print('NG (', bat, x,\n",
    "                      ') orig: ', orig, ' check: ', check)\n",
    "                ok = False\n",
    "            else:\n",
    "                print('OK (', bat, x,\n",
    "                      ') orig: ', orig, ' check: ', check)\n",
    "\n",
    "    if ok:\n",
    "        print('# verify: PASSED')\n",
    "    else:\n",
    "        print('# verify: FAILED')\n",
    "\n",
    "    vthread.finish()\n",
    "\n",
    "\n",
    "th = vthread.Thread(m, 'th_ctrl', clk, rst, ctrl)\n",
    "fsm = th.start()\n",
    "\n",
    "uut = m.Instance(targ, 'uut',\n",
    "                 params=m.connect_params(targ),\n",
    "                 ports=m.connect_ports(targ))\n",
    "\n",
    "# simulation.setup_waveform(m, uut)\n",
    "simulation.setup_clock(m, clk, hperiod=5)\n",
    "init = simulation.setup_reset(m, resetn, m.make_reset(), period=100, polarity='low')\n",
    "\n",
    "init.add(\n",
    "    Delay(10000000),\n",
    "    Systask('finish'),\n",
    ")\n",
    "\n",
    "# output source code\n",
    "if filename is not None:\n",
    "    m.to_verilog(filename)\n",
    "\n",
    "# run simulation\n",
    "sim = simulation.Simulator(m, sim=simtype)\n",
    "rslt = sim.run(outputfile=outputfile)\n",
    "\n",
    "print(rslt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
